{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tGvUfoNWrhHg",
        "outputId": "278f7a2a-52a0-4854-9302-5f080c814bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download the file directly from the UniMorph GitHub\n",
        "!wget -O eng_unimorph.tsv https://raw.githubusercontent.com/unimorph/eng/master/eng\n",
        "\n",
        "# Load into a DataFrame\n",
        "df = pd.read_csv(\"eng_unimorph.tsv\", sep=\"\\t\", header=None, names=[\"lemma\", \"form\", \"features\"])\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQCnNbimrtK2",
        "outputId": "499e7579-09d9-4cae-e479-5931a0025a13"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-12 21:31:52--  https://raw.githubusercontent.com/unimorph/eng/master/eng\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18022905 (17M) [text/plain]\n",
            "Saving to: ‘eng_unimorph.tsv’\n",
            "\n",
            "eng_unimorph.tsv    100%[===================>]  17.19M  79.8MB/s    in 0.2s    \n",
            "\n",
            "2025-06-12 21:31:53 (79.8 MB/s) - ‘eng_unimorph.tsv’ saved [18022905/18022905]\n",
            "\n",
            "       lemma         form      features\n",
            "0  microtome   microtomes          N;PL\n",
            "1  microtome   microtomes    V;PRS;3;SG\n",
            "2  microtome  microtoming  V;V.PTCP;PRS\n",
            "3  microtome   microtomed         V;PST\n",
            "4  microtome   microtomed  V;V.PTCP;PST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values and duplicates\n",
        "df = df.dropna().drop_duplicates()\n",
        "\n",
        "# Keep only rows where both lemma and form are alphabetic\n",
        "df = df[df['lemma'].str.isalpha() & df['form'].str.isalpha()]\n",
        "\n",
        "# Lowercase\n",
        "df['lemma'] = df['lemma'].str.lower()\n",
        "df['form'] = df['form'].str.lower()"
      ],
      "metadata": {
        "id": "trkq9e5Pt61O"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "def is_single_token(word):\n",
        "    ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "    return len(ids) == 1 and word in tokenizer.get_vocab()\n",
        "\n",
        "# Batch process lemmas and forms\n",
        "lemmas = df['lemma'].tolist()\n",
        "forms = df['form'].tolist()\n",
        "\n",
        "lemma_encodings = tokenizer.batch_encode_plus(lemmas, add_special_tokens=False)['input_ids']\n",
        "form_encodings = tokenizer.batch_encode_plus(forms, add_special_tokens=False)['input_ids']\n",
        "\n",
        "# Both lemma and form must be a single token and not equal\n",
        "mask = [\n",
        "    len(l) == 1 and len(f) == 1 and lemmas[i] != forms[i]\n",
        "    for i, (l, f) in enumerate(zip(lemma_encodings, form_encodings))\n",
        "]\n",
        "\n",
        "filtered_df = df[mask]\n",
        "print(f\"Filtered pairs: {len(filtered_df)}\")\n",
        "print(filtered_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deHoq-h_t_jX",
        "outputId": "4e13f4c9-4a4f-462d-aa75-84115d13a25e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered pairs: 1077\n",
            "      lemma     form      features\n",
            "6       eat   eating  V;V.PTCP;PRS\n",
            "93     mile    miles          N;PL\n",
            "354    lead  leading  V;V.PTCP;PRS\n",
            "799   fillo   fillos          N;PL\n",
            "1800  serve   served         V;PST\n",
            "1801  serve   served  V;V.PTCP;PST\n",
            "2157   city   cities          N;PL\n",
            "2583   dure   during  V;V.PTCP;PRS\n",
            "2695  belle   belles          N;PL\n",
            "2713  place   places          N;PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.to_csv(\"filtered_unimorph_pairs.csv\", index=False)"
      ],
      "metadata": {
        "id": "p-ho8JOKwO8U"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Get the embedding matrix\n",
        "embedding_matrix = model.get_input_embeddings().weight.data  # shape: (vocab_size, hidden_dim)"
      ],
      "metadata": {
        "id": "7CoGUeeN0HeX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_id(word):\n",
        "    # Returns the token id if word is a single token, else None\n",
        "    ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "    return ids[0] if len(ids) == 1 else None\n",
        "\n",
        "# Add token ids to DataFrame (should already be single tokens from filtering)\n",
        "filtered_df['lemma_id'] = filtered_df['lemma'].apply(get_token_id)\n",
        "filtered_df['form_id'] = filtered_df['form'].apply(get_token_id)\n",
        "\n",
        "# Drop any rows where tokenization failed (should be none, but just in case)\n",
        "filtered_df = filtered_df.dropna(subset=['lemma_id', 'form_id'])\n",
        "filtered_df['lemma_id'] = filtered_df['lemma_id'].astype(int)\n",
        "filtered_df['form_id'] = filtered_df['form_id'].astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dymA1iIY0PhR",
        "outputId": "ef0f4b6a-8b68-4ff3-fbcc-486885f5a93b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-3851713354>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['lemma_id'] = filtered_df['lemma'].apply(get_token_id)\n",
            "<ipython-input-47-3851713354>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['form_id'] = filtered_df['form'].apply(get_token_id)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensor for indexing\n",
        "lemma_ids = torch.tensor(filtered_df['lemma_id'].values)\n",
        "form_ids = torch.tensor(filtered_df['form_id'].values)\n",
        "\n",
        "# Get embeddings\n",
        "lemma_embeddings = embedding_matrix[lemma_ids]\n",
        "form_embeddings = embedding_matrix[form_ids]"
      ],
      "metadata": {
        "id": "HVYtCRMF0WNn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"lemma_embeddings.npy\", lemma_embeddings.cpu().numpy())\n",
        "np.save(\"form_embeddings.npy\", form_embeddings.cpu().numpy())\n",
        "filtered_df.to_csv(\"embedding_pairs_metadata.csv\", index=False)"
      ],
      "metadata": {
        "id": "h8Adjlro0aRn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lemma embeddings shape:\", lemma_embeddings.shape)\n",
        "print(\"Form embeddings shape:\", form_embeddings.shape)\n",
        "print(\"Sample lemma embedding:\", lemma_embeddings[0][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Pk3PVX0r6U",
        "outputId": "52b33425-16d6-42eb-ce21-4978ec98a0ce"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma embeddings shape: torch.Size([1077, 768])\n",
            "Form embeddings shape: torch.Size([1077, 768])\n",
            "Sample lemma embedding: tensor([0.0729, 0.1250, 0.2510, 0.4988, 0.0096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "lemma_embeddings = torch.tensor(np.load(\"lemma_embeddings.npy\"))\n",
        "form_embeddings = torch.tensor(np.load(\"form_embeddings.npy\"))"
      ],
      "metadata": {
        "id": "0M8kBUXq2Hj0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    lemma_embeddings, form_embeddings, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "wm2d3f8O2NhT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MLPMapper(nn.Module):\n",
        "    def __init__(self, dim, hidden=512):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLPMapper(X_train.shape[1]).to(device)\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(1000):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X_train)\n",
        "    loss = loss_fn(pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Jybt1o2QOb",
        "outputId": "9a80e8f0-91f6-44ee-ee04-cec5f29ca2c3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.0287\n",
            "Epoch 40, Loss: 0.0256\n",
            "Epoch 60, Loss: 0.0229\n",
            "Epoch 80, Loss: 0.0202\n",
            "Epoch 100, Loss: 0.0178\n",
            "Epoch 120, Loss: 0.0158\n",
            "Epoch 140, Loss: 0.0142\n",
            "Epoch 160, Loss: 0.0129\n",
            "Epoch 180, Loss: 0.0118\n",
            "Epoch 200, Loss: 0.0109\n",
            "Epoch 220, Loss: 0.0101\n",
            "Epoch 240, Loss: 0.0095\n",
            "Epoch 260, Loss: 0.0089\n",
            "Epoch 280, Loss: 0.0084\n",
            "Epoch 300, Loss: 0.0080\n",
            "Epoch 320, Loss: 0.0076\n",
            "Epoch 340, Loss: 0.0072\n",
            "Epoch 360, Loss: 0.0069\n",
            "Epoch 380, Loss: 0.0067\n",
            "Epoch 400, Loss: 0.0064\n",
            "Epoch 420, Loss: 0.0062\n",
            "Epoch 440, Loss: 0.0060\n",
            "Epoch 460, Loss: 0.0058\n",
            "Epoch 480, Loss: 0.0057\n",
            "Epoch 500, Loss: 0.0055\n",
            "Epoch 520, Loss: 0.0054\n",
            "Epoch 540, Loss: 0.0053\n",
            "Epoch 560, Loss: 0.0051\n",
            "Epoch 580, Loss: 0.0050\n",
            "Epoch 600, Loss: 0.0049\n",
            "Epoch 620, Loss: 0.0049\n",
            "Epoch 640, Loss: 0.0048\n",
            "Epoch 660, Loss: 0.0047\n",
            "Epoch 680, Loss: 0.0046\n",
            "Epoch 700, Loss: 0.0046\n",
            "Epoch 720, Loss: 0.0045\n",
            "Epoch 740, Loss: 0.0045\n",
            "Epoch 760, Loss: 0.0044\n",
            "Epoch 780, Loss: 0.0044\n",
            "Epoch 800, Loss: 0.0043\n",
            "Epoch 820, Loss: 0.0043\n",
            "Epoch 840, Loss: 0.0043\n",
            "Epoch 860, Loss: 0.0042\n",
            "Epoch 880, Loss: 0.0042\n",
            "Epoch 900, Loss: 0.0042\n",
            "Epoch 920, Loss: 0.0041\n",
            "Epoch 940, Loss: 0.0041\n",
            "Epoch 960, Loss: 0.0041\n",
            "Epoch 980, Loss: 0.0041\n",
            "Epoch 1000, Loss: 0.0040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(X_test)\n",
        "    cosine_sim = F.cosine_similarity(pred, y_test, dim=1)\n",
        "    avg_cosine = cosine_sim.mean().item()\n",
        "print(f\"Average Cosine Similarity on Test Set: {avg_cosine:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvImTMgS2bqp",
        "outputId": "0f1516a0-8f71-4588-c661-3512c2cd14bb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Cosine Similarity on Test Set: 0.7494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_accuracy(preds, targets, k=5):\n",
        "    # preds, targets: (N, D)\n",
        "    sims = torch.mm(preds, targets.t())\n",
        "    topk = sims.topk(k, dim=1).indices\n",
        "    correct = torch.arange(preds.size(0), device=preds.device)\n",
        "    hits = [(correct[i] in topk[i]) for i in range(preds.size(0))]\n",
        "    return sum(hits) / len(hits)\n",
        "\n",
        "with torch.no_grad():\n",
        "    acc = top_k_accuracy(pred, y_test, k=5)\n",
        "print(f\"Top-5 Nearest Neighbor Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxYi1rP2h83",
        "outputId": "b2e68afa-907e-43a4-cea8-c657e04e8404"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 Nearest Neighbor Accuracy: 89.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8mRTgmqBfDi"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}